---
title: "Clinical Trials"
author: "Rafael Sommer"
date: "05/05/2020"
output: html_document
---
# Clinical Trials common used scripts
This document will contain code that exemplifies common clinical trial practices as well as templates for personal designs. I used some of the Clinical Trial DataCamp course to extract some of the code, and libraries.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo = FALSE}
library(compareGroups)
library(ggplot2)
library(blockrand)
```
### Libraries used and its version
#### - Package compareGroups version 4.4.1
#### - Package blockrand version 1.5

# Randomization
## Simple and block randomization
This do not take any extra factors in account to assign groups
```{r}
treatment <- c("A","B")
# list <- sample(treatment, x, replace = TRUE)
# cat(list,sep="\n") # Command to show concatenated list
```
This method, however, can generate unbalanced group for small sample size, in order to correct for that, we may choose a block randomization design:
```{r}
# Template
num = 10 # Minimum number of subjects
numArm = 2 # Number of treatments arms
x = 2 # Block size (randomizes x * numArm)
y = 2 # Block size (same, you can use several sizes for random diferent blocks)
block.list <- blockrand(n = num, num.levels = numArm, block.sizes = c(x,y))

# E.G
block.list <- blockrand(n = 50, num.levels = 2, block.sizes = c(2,2))
head(block.list)
# To make the end of each block unpredictable, you may allow blocks to have different sizes at random, for eg:
block.list <- blockrand(n = 20, num.levels = 2, block.sizes = c(1,2))
# You can see that some blocks have a size = 2 (n*1) or 4 (n*2)
block.list
```
## Stratified randomization
This is helpful if you want to balance the treatment arms for certain known variable, randomization carries a separate randomization for each stratified group, so for example:

```{r}
diabetic <- blockrand(n = 20, num.levels = 2, block.sizes = c(1,2,3), 
                      stratum = "diabetic")
non_diabetic <- blockrand(n = 20, num.levels = 2, block.sizes = c(1,2,3), 
                      stratum = "non_diabetic")

table(diabetic$treatment)
table(non_diabetic$treatment)
```
This code generate two separated lists for each strat, so included patients will be assigned to one or other depending on diabetes status.


# Sample size and power calculation
## Most basic sample size calculations include normally distributed continuos endpoints and proportion endpoints. Those can be calculated as the following: 
```{r}
# Differences in mean change template
d = 1 # True difference in means (effect size)
s = 0.5 # Expected mean variability (standard deviation)
b = 0.8 # Desired power (1-b)
a = 0.05 # Desired significance level, type I error prob (1-a)
t = "two.sample" # Type of t-test, could be one.sample, two.sample, paired
alt = "two.sided" # one.sided or two.sided alternative hypotesis
# Example
samplesize <- power.t.test(delta = d, 
                           sd = s, 
                           power = b, 
                           sig.level = a,
                           type = t,
                           alternative = alt)
samplesize
# Maybe useful to plot a range of powers for a range of effect sizes
drange = seq(0.25,1.5, by=0.15)
sample_calc <- NULL
for(i in 1:length(drange)){
  sample_calc[i] <- power.t.test(delta = drange[i], sd = 0.5, power = 0.8)$n
}
samples_table <- data.frame(n = sample_calc, effect_size = drange)

ggplot(data=samples_table, aes(x=effect_size, y=n)) + 
  geom_line() + 
  geom_point() + 
  ggtitle("Sample Size Scenarios") + 
  xlab("Treatment Difference") +
  ylab("Patients per Group")

# Differences in proportions (2 groups) template
p1 = 0.3
p2 = 0.1
a = 0.05
b = 0.8 
alt = "two.sided"
  
power.prop.test(p1 = p1 , p2 = p2 , 
                sig.level = a,
                power = b ,
                alternative = alt)

```
## More complex sample size calculations:

```{r}
# Sample size calculation for correlated data (nested, longitudinal)
N = "x" # Total subjects  
n = 3 # Number for repeated measures / correlated measures
sig2within = 0.2 # Variability for the within-subject
sig2between = 0.15 # Estimated variability between-subjects
mindiff = 0.35 # Minimun treatment effect-size
alpha = 0.05 # significance level
pow = 0.8 # desired power
tau = 1 # trial total duration
time = 1 # tau unit (for 2 year trial use tau = 2 ; time = 12)

sig2 = time*(n-1)*sig2within/(tau^2*n*(n+1))+sig2between
sig2

N = (qnorm(1-alpha/2)+qnorm(pow))^2*2*sig2/mindiff^2
print(c("n per group", ceiling(N)))

# There is the option of using the longpower library
library(longpower)
# liu.liang.linear.power(delta = 0.35,
                       #)

```

# Dataset Exploration
We will use the compareGroups library which facilitate comparing for baseline group characteristics and building tables. LetÂ´s do a basic baseline comparation example:
```{r, echo = TRUE}
# Template
#baseline_info <- compareGroups(group ~ x1 + x2 + ... + xn, data = dataset)
#baseline_table <- createTable(baseline_info, show.ratio = F, show.p.overall = F)
#baseline_table
```